{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "import implicit\n",
    "from sklearn import metrics\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.width = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Summary\n",
    "\n",
    "1. Based on Sijo's work, tried other algorithms of Implicit package.\n",
    "\n",
    "2. Best auc_roc was 0.808 for LogisticMatrixFactorization (best number of factors is 35), but it's still lower than 0.836.\n",
    "\n",
    "3. Test hypothesis: tried running recommendor on members who participate at least 3 groups. Because I though there was too few information in people who participate only 1 or 2 groups. The best result was 0.736 (with factor of 16), though it's lower than running on the whole data, but it's higher than 0.725 of recommending the most popular groups. \n",
    "\n",
    "4. Which means maybe we should recommend the most popular groups to those who only participate ne or two groups. And make a more personalized recommendor for more active members. \n",
    "\n",
    "## Next step:\n",
    "\n",
    "try algorithms in this package: https://github.com/NicolasHug/Surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work flow\n",
    "1. pre-processing data\n",
    "    - merger member, event, rsvp\n",
    "    - scale the number of events a member participated\n",
    "    - get member_group matrix\n",
    "2. split to train data set and test data set\n",
    "    - my question: it looks like the author only take out the participated group\n",
    "3. run the model\n",
    "4. compare the result\n",
    "\n",
    "[to do]\n",
    "5. see if recommendation makes sense\n",
    "    - extract one member \n",
    "    - see what group he/she participated\n",
    "    - see what recommendation we made\n",
    "    - try to tell a story about this\n",
    "    - make few more examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read-in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:2: DtypeWarning: Columns (36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "<string>:2: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "<string>:2: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 54.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#load the rsvp, member and events data \n",
    "rsvp = pd.read_csv('rsvps_all_new.csv')\n",
    "member = pd.read_csv('members_new.csv',encoding='latin-1')\n",
    "events = pd.read_csv('events_all_new.csv',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = pd.read_csv('groups_austin.csv',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of dfs\n",
    "\n",
    "#### New\n",
    "\n",
    "__rsvp__ we have 34592 event.id, 6740 member_id\n",
    "\n",
    "__member__ we can get 299630 member_id, and 2273 group_id\n",
    "\n",
    "__events__ we can get 35629 id, and 872 group_id, 872 group.name\n",
    "\n",
    "#### Before\n",
    "\n",
    "__rsvp__ we have 541 event_id, 2958 member_id\n",
    "\n",
    "__member__ we can get 1087923 member_id, and 12546 group_id\n",
    "\n",
    "__events__ we can get 5807 event_id, and 341 group_id, 341 group.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's in our rsvp events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['created', 'description', 'duration', 'event_url', 'fee.accepts',\n",
       "       'fee.amount', 'fee.currency', 'fee.description', 'fee.label',\n",
       "       'fee.required', 'group.created', 'group.group_lat', 'group.group_lon',\n",
       "       'group.id', 'group.join_mode', 'group.name', 'group.urlname',\n",
       "       'group.who', 'headcount', 'how_to_find_us', 'id', 'maybe_rsvp_count',\n",
       "       'name', 'photo_url', 'rsvp_limit', 'status', 'time', 'updated',\n",
       "       'utc_offset', 'venue.address_1', 'venue.address_2', 'venue.city',\n",
       "       'venue.country', 'venue.id', 'venue.lat',\n",
       "       'venue.localized_country_name', 'venue.lon', 'venue.name',\n",
       "       'venue.phone', 'venue.repinned', 'venue.state', 'venue.zip',\n",
       "       'visibility', 'waitlist_count', 'why', 'yes_rsvp_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = events['id'].map(lambda x: x in rsvp['event.id'].values)\n",
    "events_masked = events[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34565, 46)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_masked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1980"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(events_masked['name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TX    25982\n",
       "tx     2759\n",
       "al      150\n",
       "Te      149\n",
       "CA       57\n",
       "HI       13\n",
       "FL        2\n",
       "AR        2\n",
       "WA        1\n",
       "MN        1\n",
       "VA        1\n",
       "NM        1\n",
       "Name: venue.state, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# events_masked['venue.localized_country_name'].value_counts()\n",
    "events_masked['venue.state'].value_counts()\n",
    "# events_masked['created'].max() # date varies from 2017 to 2010"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the location vary that much, our reccomendation will not work. Because ppl in NY are not likely to participate events/ join groupd in CA. So they are basically two sets of data. We can improve our model by splitting them into different groups and train a model for each other to improve the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.16 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>rsvp_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10023</td>\n",
       "      <td>6682417</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10023</td>\n",
       "      <td>13480894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10023</td>\n",
       "      <td>155423252</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10023</td>\n",
       "      <td>161784042</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10023</td>\n",
       "      <td>201386263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group_id  member_id  rsvp_sum\n",
       "0     10023    6682417         1\n",
       "1     10023   13480894         1\n",
       "2     10023  155423252         3\n",
       "3     10023  161784042         1\n",
       "4     10023  201386263         1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#preprocesssing\n",
    "main_data = pd.merge(rsvp, events, left_on= 'event.id', right_on='id', how='inner')\n",
    "temp_data = main_data[['event.id', 'member.member_id', 'group.id_x', 'group.name']] \n",
    "main_data_2 = temp_data.groupby(['group.id_x','member.member_id']).size().reset_index()\n",
    "main_data_2.columns = ['group_id', 'member_id','rsvp_sum']\n",
    "main_data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: what is rsvp_sum?????\n",
    "That means this member participated X events held by this group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In new data 17.7% of members joined more than 1 group\n",
    "\n",
    "#### <font color='red'>In old data, 97% of members joined only one group...we need more data/ or data that focus on one city...</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8699, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6740"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_join_number = main_data_2['member_id'].value_counts()\n",
    "len(main_join_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17700296735905044"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(main_join_number > 1)/len(main_join_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q: why scale?\n",
    "The higher the scale, means the person participated more events held by the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>rsvp_sum</th>\n",
       "      <th>rsvp_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [group_id, member_id, rsvp_sum, rsvp_total]\n",
       "Index: []"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#standardizing to 1 - 10 scale \n",
    "main_data_2['rsvp_total'] = 1 + (main_data_2['rsvp_sum']-main_data_2['rsvp_sum'].min())*(10-1)/(main_data_2['rsvp_sum'].max()-main_data_2['rsvp_sum'].min())\n",
    "main_data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2891, 37)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### groups has category.name, but I can't match any variables in member\n",
    "#### I also try to use topics to match, but didn't work out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tech                    566\n",
       "career/business         465\n",
       "health/wellbeing        218\n",
       "socializing             168\n",
       "new age/spirituality    143\n",
       "Name: category.name, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups['category.name'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = groups[groups['id'] == 6671492]['topics'].values[0]\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chop off members who only participate one group or two groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = pd.merge(rsvp, events, left_on= 'event.id', right_on='id', how='inner')\n",
    "temp_data = main_data[['event.id', 'member.member_id', 'group.id_x', 'group.name']] \n",
    "main_data_2 = temp_data.groupby(['group.id_x','member.member_id']).size().reset_index()\n",
    "main_data_2.columns = ['group_id', 'member_id','rsvp_sum']\n",
    "main_data_2['rsvp_total'] = 1 + (main_data_2['rsvp_sum']-main_data_2['rsvp_sum'].min())*(10-1)/(main_data_2['rsvp_sum'].max()-main_data_2['rsvp_sum'].min())\n",
    "main_data_2 = main_data_2[main_data_2['rsvp_sum']<=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7230, 4)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce sparse_item_user and sparse_user_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = main_data_2.dropna()\n",
    "data = data.copy()\n",
    "\n",
    "# Converting the numbers to categories to be used for creating the categorical codes to avoid using long hash keys \n",
    "data['member_id'] = data['member_id'].astype('category')\n",
    "data['group_id'] = data['group_id'].astype('category')\n",
    "\n",
    "#cat.codes creates a categorical id for the users and artists\n",
    "data['user_id'] = data['member_id'].cat.codes\n",
    "data['grp_id'] = data['group_id'].cat.codes\n",
    "\n",
    "# The implicit library expects data as a item-user matrix so we\n",
    "# create two matrices, one for fitting the model (item-user) \n",
    "# and one for recommendations (user-item)\n",
    "\n",
    "# sparse_user: row is item\n",
    "sparse_item_user = sparse.csr_matrix((data['rsvp_total'].astype(float), (data['grp_id'], data['user_id'])))\n",
    "\n",
    "# sparse_user: row is user\n",
    "sparse_user_item = sparse.csr_matrix((data['rsvp_total'].astype(float), (data['user_id'], data['grp_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### codes from reference...helps me to understand what we're trying to do here\n",
    "\n",
    "# customers = list(np.sort(grouped_purchased.CustomerID.unique())) # Get our unique customers\n",
    "# products = list(grouped_purchased.StockCode.unique()) # Get our unique products that were purchased\n",
    "# quantity = list(grouped_purchased.Quantity) # All of our purchases\n",
    "\n",
    "# rows = grouped_purchased.CustomerID.astype('category', categories = customers).cat.codes \n",
    "# # Get the associated row indices\n",
    "# cols = grouped_purchased.StockCode.astype('category', categories = products).cat.codes \n",
    "# # Get the associated column indices\n",
    "# purchases_sparse = sparse.csr_matrix((quantity, (rows, cols)), shape=(len(customers), len(products)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To check sparsity\n",
    "According to https://jessesw.com/Rec-System/ _\"For collaborative filtering to work, the maximum sparsity you could get away with would probably be about 99.5% or so. We are well below this, so we should be able to get decent results.\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.81142852671691"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_size = sparse_user_item.shape[0]*sparse_user_item.shape[1] # Number of possible interactions in the matrix\n",
    "num_purchases = len(sparse_user_item.nonzero()[0]) # Number of items interacted with\n",
    "sparsity = 100*(1 - (num_purchases/matrix_size))\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train(ratings, pct_test = 0.2):\n",
    "    '''\n",
    "    This function will take in the original user-item matrix and \"mask\" a percentage of the original ratings where a\n",
    "    user-item interaction has taken place for use as a test set. The test set will contain all of the original ratings, \n",
    "    while the training set replaces the specified percentage of them with a zero in the original ratings matrix. \n",
    "    \n",
    "    parameters: \n",
    "    \n",
    "    ratings - the original ratings matrix from which you want to generate a train/test set. Test is just a complete\n",
    "    copy of the original set. This is in the form of a sparse csr_matrix. \n",
    "    \n",
    "    pct_test - The percentage of user-item interactions where an interaction took place that you want to mask in the \n",
    "    training set for later comparison to the test set, which contains all of the original ratings. \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    training_set - The altered version of the original data with a certain percentage of the user-item pairs \n",
    "    that originally had interaction set back to zero.\n",
    "    \n",
    "    test_set - A copy of the original ratings matrix, unaltered, so it can be used to see how the rank order \n",
    "    compares with the actual interactions.\n",
    "    \n",
    "    user_inds - From the randomly selected user-item indices, which user rows were altered in the training data.\n",
    "    This will be necessary later when evaluating the performance via AUC.\n",
    "    '''\n",
    "    test_set = ratings.copy() # Make a copy of the original set to be the test set. \n",
    "    test_set[test_set != 0] = 1 # Store the test set as a binary preference matrix\n",
    "    \n",
    "    training_set = ratings.copy() # Make a copy of the original data we can alter as our training set. \n",
    "    \n",
    "    nonzero_inds = training_set.nonzero() # Find the indices in the ratings data where an interaction exists\n",
    "    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1])) # Zip these pairs together of item,user index into list\n",
    "    \n",
    "    random.seed(0) # Set the random seed to zero for reproducibility\n",
    "    \n",
    "    num_samples = int(np.ceil(pct_test*len(nonzero_pairs))) # Round the number of samples needed to the nearest integer\n",
    "    samples = random.sample(nonzero_pairs, num_samples) # Sample a random number of item-user pairs without replacement\n",
    "\n",
    "    item_inds = [index[0] for index in samples] # Get the item row indices\n",
    "\n",
    "    user_inds = [index[1] for index in samples] # Get the user column indices\n",
    "    \n",
    "    training_set[item_inds, user_inds] = 0 # Assign all of the randomly chosen user-item pairs to zero\n",
    "    training_set.eliminate_zeros() # Get rid of zeros in sparse array storage after update to save space\n",
    "    mask = {}\n",
    "    #reference dictionary\n",
    "    \n",
    "    return training_set, test_set, list(set(user_inds)) # Output the unique list of user columns that were altered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q: Why do we use item_user here?\n",
    "Guess it's because followed http://www.benfrederickson.com/matrix-factorization/\n",
    "\n",
    "Note in https://jessesw.com/Rec-System/, the author actually used user as row. Which I think makes more sense to our case, since we are making reccomendation to users. \n",
    "\n",
    "But here says the model takes item_user matrix https://implicit.readthedocs.io/en/latest/als.html, therefore I believe Sijo did it right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20% of the data has been masked for this exercise\n",
    "product_train, product_test, product_users_altered = make_train(sparse_item_user, pct_test = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_users_altered) ## we randomly chose 20% of ppl and take out the members' records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: what is 'alpha' and 'factors'\n",
    "can find answer here: https://jessesw.com/Rec-System/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0dc874656d14e4182ea52dbc98a548d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the als model and fit it using the sparse item-user matrix\n",
    "# Parameters that we have chosen\n",
    "# 1. factors = 20 -- Latent factors for user and item vectors\n",
    "# 2. iterations = 20 -- Number of iterations to use while fitting the data\n",
    "# 3. regularization = 0.1 -- regularization constant to be used in the cost function\n",
    "\n",
    "# model = implicit.als.AlternatingLeastSquares(factors=20, regularization=0.1, iterations=40)\n",
    "\n",
    "model = implicit.lmf.LogisticMatrixFactorization(factors=16, regularization=0.1, iterations=40)\n",
    "\n",
    "# Calculate the confidence by multiplying it by our alpha value.(alpha value corresponds to the confidence metric \n",
    "# that we discussed earlier)\n",
    "\n",
    "alpha_val = 15\n",
    "data_conf = (product_train * alpha_val).astype('double')\n",
    "\n",
    "# We have used an alpha_val of 15 after performing some iterations with different alpha values\n",
    "#Fit the model\n",
    "model.fit(product_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of group vector matrix :  (678, 18)\n",
      "Shape of member vector matrix :  (5655, 18)\n"
     ]
    }
   ],
   "source": [
    "item_vecs = model.item_factors\n",
    "user_vecs = model.user_factors\n",
    "\n",
    "print('Shape of group vector matrix : ', item_vecs.shape)\n",
    "print('Shape of member vector matrix : ', user_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_score(predictions, test):\n",
    "    '''\n",
    "    This simple function will output the area under the curve using sklearn's metrics. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    - predictions: your prediction output\n",
    "    \n",
    "    - test: the actual target result you are comparing to\n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    - AUC (area under the Receiver Operating Characterisic curve)\n",
    "    '''\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test, predictions)\n",
    "    return metrics.auc(fpr, tpr)\n",
    "\n",
    "def calc_mean_auc(training_set, altered_users, predictions, test_set):\n",
    "    '''\n",
    "    This function will calculate the mean AUC by user for any user that had their user-item matrix altered. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    training_set - The training set resulting from make_train, where a certain percentage of the original\n",
    "    user/item interactions are reset to zero to hide them from the model \n",
    "    \n",
    "    predictions - The matrix of your predicted ratings for each user/item pair as output from the implicit MF.\n",
    "    These should be stored in a list, with user vectors as item zero and item vectors as item one. \n",
    "    \n",
    "    altered_users - The indices of the users where at least one user/item pair was altered from make_train function\n",
    "    \n",
    "    test_set - The test set constucted earlier from make_train function\n",
    "    \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    The mean AUC (area under the Receiver Operator Characteristic curve) of the test set only on user-item interactions\n",
    "    there were originally zero to test ranking ability in addition to the most popular items as a benchmark.\n",
    "    '''\n",
    "    \n",
    "    store_auc = [] # An empty list to store the AUC for each user that had an item removed from the training set\n",
    "    popularity_auc = [] # To store popular AUC scores\n",
    "    pop_items = np.array(test_set.sum(axis = 1)).reshape(-1) # Get sum of item iteractions to find most popular\n",
    "    item_vecs = predictions[1]\n",
    "    for user in altered_users: # Iterate through each user that had an item altered\n",
    "        training_column = training_set[:,user].toarray().reshape(-1) # Get the training set column\n",
    "        zero_inds = np.where(training_column == 0) # Find where the interaction had not yet occurred\n",
    "        \n",
    "        # Get the predicted values based on our user/item vectors\n",
    "        user_vec = predictions[0][user,:]\n",
    "        pred = user_vec.dot(item_vecs).toarray()[0,zero_inds].reshape(-1)\n",
    "        \n",
    "        # Get only the items that were originally zero\n",
    "        # Select all ratings from the MF prediction for this user that originally had no iteraction\n",
    "        actual = test_set[:,user].toarray()[zero_inds,0].reshape(-1)\n",
    "        \n",
    "        # Select the binarized yes/no interaction pairs from the original full data\n",
    "        # that align with the same pairs in training \n",
    "        pop = pop_items[zero_inds] # Get the item popularity for our chosen items\n",
    "#         pop = pop/np.max(pop)\n",
    "        \n",
    "        store_auc.append(auc_score(pred, actual)) # Calculate AUC for the given user and store\n",
    "        \n",
    "        popularity_auc.append(auc_score(pop, actual)) # Calculate AUC using most popular and score\n",
    "\n",
    "#         print('user', user)\n",
    "#         print('zero_inds', zero_inds)\n",
    "#         print('pred', pred)\n",
    "#         print('actual', actual)\n",
    "#         print('pop', pop)\n",
    "#         print('pred auc', auc_score(pred, actual))       \n",
    "#         print('pop auc', auc_score(pop, actual))\n",
    "    # End users iteration\n",
    "#         print('======================')\n",
    "    \n",
    "    return float('%.3f'%np.mean(store_auc)), float('%.3f'%np.mean(popularity_auc))  \n",
    "   # Return the mean AUC rounded to three decimal places for both test and popularity benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just chek pop_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop_items = np.array(product_test.sum(axis = 1)).reshape(-1)\n",
    "\n",
    "# user = 2052\n",
    "# training_column = product_train[:,user].toarray().reshape(-1)\n",
    "# zero_inds = np.where(training_column == 0)\n",
    "# pop = pop_items[zero_inds]\n",
    "# # pop = pop[ pop == np.max(pop)]\n",
    "\n",
    "# pop_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our recommendation is not good. \n",
    "The first number is the AUC of our model, the second is AUC if we recommend the most popular event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### below is ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.54, 0.836)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc_mean_auc(product_train, product_users_altered,\n",
    "#               [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)], product_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### below is BayesianPersonalizedRanking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.509, 0.836)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc_mean_auc(product_train, product_users_altered,\n",
    "#               [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)], product_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticMatrixFactorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.793, 0.829)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_mean_auc(product_train, product_users_altered,\n",
    "              [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)], product_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 46.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "auc = dict()\n",
    "for i in range(2,51):\n",
    "    model = implicit.lmf.LogisticMatrixFactorization(factors=i, regularization=0.1, iterations=40)\n",
    "    alpha_val = 15\n",
    "    data_conf = (product_train * alpha_val).astype('double')\n",
    "    model.fit(product_train, show_progress=False)\n",
    "    item_vecs = model.item_factors\n",
    "    user_vecs = model.user_factors\n",
    "    \n",
    "    auc[i] = calc_mean_auc(product_train, product_users_altered,\n",
    "                  [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)], product_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16    0.739\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = pd.Series(auc)\n",
    "check[check == check.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticMatrixFactorization for rsvp_sum >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.669, 0.725)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_mean_auc(product_train, product_users_altered,\n",
    "              [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)], product_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 44.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "auc = dict()\n",
    "for i in range(2,51):\n",
    "    model = implicit.lmf.LogisticMatrixFactorization(factors=i, regularization=0.1, iterations=40)\n",
    "    alpha_val = 15\n",
    "    data_conf = (product_train * alpha_val).astype('double')\n",
    "    model.fit(product_train, show_progress=False)\n",
    "    item_vecs = model.item_factors\n",
    "    user_vecs = model.user_factors\n",
    "    \n",
    "    auc[i] = calc_mean_auc(product_train, product_users_altered,\n",
    "                  [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)], product_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14    0.727\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = pd.Series(auc)\n",
    "check[check == check.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A show case of our recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['group_id', 'member_id', 'rsvp_sum', 'rsvp_total', 'user_id', 'grp_id'], dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['created', 'description', 'duration', 'event_url', 'fee.accepts',\n",
       "       'fee.amount', 'fee.currency', 'fee.description', 'fee.label',\n",
       "       'fee.required', 'group.created', 'group.group_lat', 'group.group_lon',\n",
       "       'group.id', 'group.join_mode', 'group.name', 'group.urlname',\n",
       "       'group.who', 'headcount', 'how_to_find_us', 'id', 'maybe_rsvp_count',\n",
       "       'name', 'photo_url', 'rsvp_limit', 'status', 'time', 'updated',\n",
       "       'utc_offset', 'venue.address_1', 'venue.address_2', 'venue.city',\n",
       "       'venue.country', 'venue.id', 'venue.lat',\n",
       "       'venue.localized_country_name', 'venue.lon', 'venue.name',\n",
       "       'venue.phone', 'venue.repinned', 'venue.state', 'venue.zip',\n",
       "       'visibility', 'waitlist_count', 'why', 'yes_rsvp_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Austin Office 365 and SharePoint User Group\n",
      "Austin Virtual Bible Study Meetup\n",
      "NBX - Austin Professional Networking Group\n",
      "Club Turnttt\n",
      "Beat Burnout With Emotional Energetic Release\n",
      "Austin Sailing Adventures\n",
      "Austin Reiki Classes/Attunement Meetup\n",
      "Weeknight Wordsmiths\n",
      "The Austin Physician Network\n",
      "Mindfulness in Nature\n"
     ]
    }
   ],
   "source": [
    "test=pd.merge(data, events[['group.name','group.id']], left_on = 'group_id', right_on = 'group.id', how = 'inner')\n",
    "test=test.drop_duplicates()\n",
    "\n",
    "# raeding chinese books group - 26243452\n",
    "\n",
    "group_id = 300\n",
    "n_similar = 10 # getting the top ten similar items\n",
    "# print (\"------------Actual group-------------------\")\n",
    "# print (test[test['grp_id'] == group_id]['group.name'])\n",
    "# print (\"------------Actual group-------------------\")\n",
    "\n",
    "# Use implicit to get similar items.\n",
    "similar = model.similar_items(group_id, 10)\n",
    "# Print the names of our most similar artists\n",
    "for group in similar:\n",
    "    idx, score = group\n",
    "    print (test['group.name'].loc[test.grp_id == idx].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>rsvp_sum</th>\n",
       "      <th>rsvp_total</th>\n",
       "      <th>user_id</th>\n",
       "      <th>grp_id</th>\n",
       "      <th>group.name</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32159</th>\n",
       "      <td>2148441</td>\n",
       "      <td>5189189</td>\n",
       "      <td>42</td>\n",
       "      <td>8.530612</td>\n",
       "      <td>86</td>\n",
       "      <td>17</td>\n",
       "      <td>SF Free School</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43415</th>\n",
       "      <td>2148441</td>\n",
       "      <td>88770122</td>\n",
       "      <td>39</td>\n",
       "      <td>7.979592</td>\n",
       "      <td>719</td>\n",
       "      <td>17</td>\n",
       "      <td>SF Free School</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108186</th>\n",
       "      <td>18177413</td>\n",
       "      <td>192517329</td>\n",
       "      <td>33</td>\n",
       "      <td>6.877551</td>\n",
       "      <td>1366</td>\n",
       "      <td>35</td>\n",
       "      <td>Bryant Park Toastmasters</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108286</th>\n",
       "      <td>18177413</td>\n",
       "      <td>195703963</td>\n",
       "      <td>50</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1429</td>\n",
       "      <td>35</td>\n",
       "      <td>Bryant Park Toastmasters</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108786</th>\n",
       "      <td>18177413</td>\n",
       "      <td>203392611</td>\n",
       "      <td>31</td>\n",
       "      <td>6.510204</td>\n",
       "      <td>1600</td>\n",
       "      <td>35</td>\n",
       "      <td>Bryant Park Toastmasters</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109386</th>\n",
       "      <td>18177413</td>\n",
       "      <td>224325846</td>\n",
       "      <td>45</td>\n",
       "      <td>9.081633</td>\n",
       "      <td>1940</td>\n",
       "      <td>35</td>\n",
       "      <td>Bryant Park Toastmasters</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114605</th>\n",
       "      <td>18468560</td>\n",
       "      <td>184845608</td>\n",
       "      <td>33</td>\n",
       "      <td>6.877551</td>\n",
       "      <td>1187</td>\n",
       "      <td>40</td>\n",
       "      <td>Lexington/Vanderbilt toastmasters public speak...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120420</th>\n",
       "      <td>26243452</td>\n",
       "      <td>78357452</td>\n",
       "      <td>31</td>\n",
       "      <td>6.510204</td>\n",
       "      <td>675</td>\n",
       "      <td>46</td>\n",
       "      <td>Reading Chinese Books</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121470</th>\n",
       "      <td>26243452</td>\n",
       "      <td>234733619</td>\n",
       "      <td>39</td>\n",
       "      <td>7.979592</td>\n",
       "      <td>2205</td>\n",
       "      <td>46</td>\n",
       "      <td>Reading Chinese Books</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        group_id  member_id  rsvp_sum  rsvp_total  user_id  grp_id  \\\n",
       "32159    2148441    5189189        42    8.530612       86      17   \n",
       "43415    2148441   88770122        39    7.979592      719      17   \n",
       "108186  18177413  192517329        33    6.877551     1366      35   \n",
       "108286  18177413  195703963        50   10.000000     1429      35   \n",
       "108786  18177413  203392611        31    6.510204     1600      35   \n",
       "109386  18177413  224325846        45    9.081633     1940      35   \n",
       "114605  18468560  184845608        33    6.877551     1187      40   \n",
       "120420  26243452   78357452        31    6.510204      675      46   \n",
       "121470  26243452  234733619        39    7.979592     2205      46   \n",
       "\n",
       "                                               group.name  rank  \n",
       "32159                                      SF Free School   3.0  \n",
       "43415                                      SF Free School   5.0  \n",
       "108186                           Bryant Park Toastmasters   7.0  \n",
       "108286                           Bryant Park Toastmasters   1.0  \n",
       "108786                           Bryant Park Toastmasters   9.0  \n",
       "109386                           Bryant Park Toastmasters   2.0  \n",
       "114605  Lexington/Vanderbilt toastmasters public speak...   7.0  \n",
       "120420                              Reading Chinese Books   9.0  \n",
       "121470                              Reading Chinese Books   5.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top member\n",
    "test['rank'] = test.rsvp_total.rank(ascending = False, method='max') \n",
    "test_1 = test[test['rank'] <10]\n",
    "test_1.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4374\u001b[0m             return self._engine.get_value(s, k,\n\u001b[1;32m-> 4375\u001b[1;33m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[0;32m   4376\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-b471c618eaa3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmember_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m6192675\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0muser_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'member_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmember_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Use the implicit recommender.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrecommended\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecommend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_user_item\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilter_already_liked_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    866\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4380\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4381\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4382\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4383\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_box\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.get_value_at\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.validate_indexer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of bounds"
     ]
    }
   ],
   "source": [
    "member_id = 6192675\n",
    "user_id = test[test['member_id'] == member_id]['user_id'][0]\n",
    "\n",
    "# Use the implicit recommender.\n",
    "recommended = model.recommend(user_id, sparse_user_item,N = 10,filter_already_liked_items = False)\n",
    "\n",
    "artists = []\n",
    "scores = []\n",
    "\n",
    "# Get artist names from ids\n",
    "for item in recommended:\n",
    "    idx, score = item\n",
    "    artists.append(test['group.name'].loc[test.grp_id == idx].iloc[0])\n",
    "    scores.append(score)\n",
    "\n",
    "# Create a dataframe of artist names and scores\n",
    "recommendations = pd.DataFrame({'artist': artists, 'score': scores})\n",
    "\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_train, product_test, product_users_altered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(678, 5655)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(678, 5655)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1353"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_users_altered)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
