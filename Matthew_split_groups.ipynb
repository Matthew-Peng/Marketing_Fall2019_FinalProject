{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This runs model on splitted dataset\n",
    "### Note:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "import implicit\n",
    "from sklearn import metrics\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.options.display.width = 100\n",
    "\n",
    "def make_train(ratings, pct_test = 0.2):\n",
    "    '''\n",
    "    This function will take in the original user-item matrix and \"mask\" a percentage of the original ratings where a\n",
    "    user-item interaction has taken place for use as a test set. The test set will contain all of the original ratings, \n",
    "    while the training set replaces the specified percentage of them with a zero in the original ratings matrix. \n",
    "    \n",
    "    parameters: \n",
    "    \n",
    "    ratings - the original ratings matrix from which you want to generate a train/test set. Test is just a complete\n",
    "    copy of the original set. This is in the form of a sparse csr_matrix. \n",
    "    \n",
    "    pct_test - The percentage of user-item interactions where an interaction took place that you want to mask in the \n",
    "    training set for later comparison to the test set, which contains all of the original ratings. \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    training_set - The altered version of the original data with a certain percentage of the user-item pairs \n",
    "    that originally had interaction set back to zero.\n",
    "    \n",
    "    test_set - A copy of the original ratings matrix, unaltered, so it can be used to see how the rank order \n",
    "    compares with the actual interactions.\n",
    "    \n",
    "    user_inds - From the randomly selected user-item indices, which user rows were altered in the training data.\n",
    "    This will be necessary later when evaluating the performance via AUC.\n",
    "    '''\n",
    "    test_set = ratings.copy() # Make a copy of the original set to be the test set. \n",
    "    test_set[test_set != 0] = 1 # Store the test set as a binary preference matrix\n",
    "    \n",
    "    training_set = ratings.copy() # Make a copy of the original data we can alter as our training set. \n",
    "    \n",
    "    nonzero_inds = training_set.nonzero() # Find the indices in the ratings data where an interaction exists\n",
    "    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1])) # Zip these pairs together of item,user index into list\n",
    "    \n",
    "    random.seed(0) # Set the random seed to zero for reproducibility\n",
    "    \n",
    "    num_samples = int(np.ceil(pct_test*len(nonzero_pairs))) # Round the number of samples needed to the nearest integer\n",
    "    samples = random.sample(nonzero_pairs, num_samples) # Sample a random number of item-user pairs without replacement\n",
    "\n",
    "    item_inds = [index[0] for index in samples] # Get the item row indices\n",
    "\n",
    "    user_inds = [index[1] for index in samples] # Get the user column indices\n",
    "    \n",
    "    training_set[item_inds, user_inds] = 0 # Assign all of the randomly chosen user-item pairs to zero\n",
    "    training_set.eliminate_zeros() # Get rid of zeros in sparse array storage after update to save space\n",
    "    mask = {}\n",
    "    #reference dictionary\n",
    "    \n",
    "    return training_set, test_set, list(set(user_inds)) # Output the unique list of user columns that were altered\n",
    "\n",
    "def auc_score(predictions, test):\n",
    "    '''\n",
    "    This simple function will output the area under the curve using sklearn's metrics. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    - predictions: your prediction output\n",
    "    \n",
    "    - test: the actual target result you are comparing to\n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    - AUC (area under the Receiver Operating Characterisic curve)\n",
    "    '''\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test, predictions)\n",
    "    return metrics.auc(fpr, tpr)\n",
    "\n",
    "def calc_mean_auc(training_set, altered_users, predictions, test_set):\n",
    "    '''\n",
    "    This function will calculate the mean AUC by user for any user that had their user-item matrix altered. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    training_set - The training set resulting from make_train, where a certain percentage of the original\n",
    "    user/item interactions are reset to zero to hide them from the model \n",
    "    \n",
    "    predictions - The matrix of your predicted ratings for each user/item pair as output from the implicit MF.\n",
    "    These should be stored in a list, with user vectors as item zero and item vectors as item one. \n",
    "    \n",
    "    altered_users - The indices of the users where at least one user/item pair was altered from make_train function\n",
    "    \n",
    "    test_set - The test set constucted earlier from make_train function\n",
    "    \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    The mean AUC (area under the Receiver Operator Characteristic curve) of the test set only on user-item interactions\n",
    "    there were originally zero to test ranking ability in addition to the most popular items as a benchmark.\n",
    "    '''\n",
    "    \n",
    "    store_auc = [] # An empty list to store the AUC for each user that had an item removed from the training set\n",
    "    popularity_auc = [] # To store popular AUC scores\n",
    "    pop_items = np.array(test_set.sum(axis = 1)).reshape(-1) # Get sum of item iteractions to find most popular\n",
    "    item_vecs = predictions[1]\n",
    "    for user in altered_users: # Iterate through each user that had an item altered\n",
    "        training_column = training_set[:,user].toarray().reshape(-1) # Get the training set column\n",
    "        zero_inds = np.where(training_column == 0) # Find where the interaction had not yet occurred\n",
    "        \n",
    "        # Get the predicted values based on our user/item vectors\n",
    "        user_vec = predictions[0][user,:]\n",
    "        pred = user_vec.dot(item_vecs).toarray()[0,zero_inds].reshape(-1)\n",
    "        \n",
    "        # Get only the items that were originally zero\n",
    "        # Select all ratings from the MF prediction for this user that originally had no iteraction\n",
    "        actual = test_set[:,user].toarray()[zero_inds,0].reshape(-1)\n",
    "        \n",
    "        # Select the binarized yes/no interaction pairs from the original full data\n",
    "        # that align with the same pairs in training \n",
    "        pop = pop_items[zero_inds] # Get the item popularity for our chosen items\n",
    "#         pop = pop/np.max(pop)\n",
    "        \n",
    "        store_auc.append(auc_score(pred, actual)) # Calculate AUC for the given user and store\n",
    "        \n",
    "        popularity_auc.append(auc_score(pop, actual)) # Calculate AUC using most popular and score\n",
    "\n",
    "#         print('user', user)\n",
    "#         print('zero_inds', zero_inds)\n",
    "#         print('pred', pred)\n",
    "#         print('actual', actual)\n",
    "#         print('pop', pop)\n",
    "#         print('pred auc', auc_score(pred, actual))       \n",
    "#         print('pop auc', auc_score(pop, actual))\n",
    "    # End users iteration\n",
    "#         print('======================')\n",
    "    \n",
    "    return float('%.3f'%np.mean(store_auc)), float('%.3f'%np.mean(popularity_auc))  \n",
    "   # Return the mean AUC rounded to three decimal places for both test and popularity benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read-in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#load the rsvp, member and events data \n",
    "rsvp = pd.read_csv('rsvps_all_new.csv')\n",
    "member = pd.read_csv('members_new.csv',encoding='latin-1')\n",
    "events = pd.read_csv('events_all_new.csv',encoding='latin-1')\n",
    "groups = pd.read_csv('groups_austin.csv',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #preprocesssing\n",
    "# main_data = pd.merge(rsvp, events, left_on= 'event.id', right_on='id', how='inner')\n",
    "# temp_data = main_data[['event.id', 'member.member_id', 'group.id_x', 'group.name']] \n",
    "# main_data_2 = temp_data.groupby(['group.id_x','member.member_id']).size().reset_index()\n",
    "# main_data_2.columns = ['group_id', 'member_id','rsvp_sum']\n",
    "# #standardizing to 1 - 10 scale \n",
    "# main_data_2['rsvp_total'] = 1 + (main_data_2['rsvp_sum']-main_data_2['rsvp_sum'].min())*(10-1)/(main_data_2['rsvp_sum'].max()-main_data_2['rsvp_sum'].min())\n",
    "# main_data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data given rsvp_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>rsvp_sum</th>\n",
       "      <th>rsvp_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10023</td>\n",
       "      <td>155423252</td>\n",
       "      <td>3</td>\n",
       "      <td>1.013343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10023</td>\n",
       "      <td>246538937</td>\n",
       "      <td>12</td>\n",
       "      <td>1.073388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10023</td>\n",
       "      <td>246755982</td>\n",
       "      <td>5</td>\n",
       "      <td>1.026686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32400</td>\n",
       "      <td>421190</td>\n",
       "      <td>12</td>\n",
       "      <td>1.073388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>39554</td>\n",
       "      <td>128804</td>\n",
       "      <td>12</td>\n",
       "      <td>1.073388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group_id  member_id  rsvp_sum  rsvp_total\n",
       "2      10023  155423252         3    1.013343\n",
       "5      10023  246538937        12    1.073388\n",
       "6      10023  246755982         5    1.026686\n",
       "9      32400     421190        12    1.073388\n",
       "11     39554     128804        12    1.073388"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data = pd.merge(rsvp, events, left_on= 'event.id', right_on='id', how='inner')\n",
    "temp_data = main_data[['event.id', 'member.member_id', 'group.id_x', 'group.name']] \n",
    "main_data_2 = temp_data.groupby(['group.id_x','member.member_id']).size().reset_index()\n",
    "main_data_2.columns = ['group_id', 'member_id','rsvp_sum']\n",
    "main_data_2['rsvp_total'] = 1 + (main_data_2['rsvp_sum']-main_data_2['rsvp_sum'].min())*(10-1)/(main_data_2['rsvp_sum'].max()-main_data_2['rsvp_sum'].min())\n",
    "#########################\n",
    "#### set here\n",
    "#########################\n",
    "main_data_2 = main_data_2[main_data_2['rsvp_sum']>2]\n",
    "main_data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce sparse_item_user and sparse_user_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = main_data_2.dropna()\n",
    "data = data.copy()\n",
    "\n",
    "# Converting the numbers to categories to be used for creating the categorical codes to avoid using long hash keys \n",
    "data['member_id'] = data['member_id'].astype('category')\n",
    "data['group_id'] = data['group_id'].astype('category')\n",
    "\n",
    "#cat.codes creates a categorical id for the users and artists\n",
    "data['user_id'] = data['member_id'].cat.codes\n",
    "data['grp_id'] = data['group_id'].cat.codes\n",
    "\n",
    "# The implicit library expects data as a item-user matrix so we\n",
    "# create two matrices, one for fitting the model (item-user) \n",
    "# and one for recommendations (user-item)\n",
    "\n",
    "# sparse_user: row is item\n",
    "sparse_item_user = sparse.csr_matrix((data['rsvp_total'].astype(float), (data['grp_id'], data['user_id'])))\n",
    "\n",
    "# sparse_user: row is user\n",
    "sparse_user_item = sparse.csr_matrix((data['rsvp_total'].astype(float), (data['user_id'], data['grp_id'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20% of the data has been masked for this exercise\n",
    "product_train, product_test, product_users_altered = make_train(sparse_item_user, pct_test = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Model - GridSearch for the best factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best factor: [20]\n",
      "best ROC AUC: [0.736]\n",
      "baseline: 0.725\n",
      "Wall time: 14.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "auc = dict()\n",
    "pop = dict()\n",
    "for i in range(11,31):\n",
    "    model = implicit.lmf.LogisticMatrixFactorization(factors=i, regularization=0.01, iterations=100)\n",
    "    alpha_val = 15\n",
    "    data_conf = (product_train * alpha_val).astype('double')\n",
    "    model.fit(product_train, show_progress=False)\n",
    "    item_vecs = model.item_factors\n",
    "    user_vecs = model.user_factors\n",
    "\n",
    "    auc[i] = calc_mean_auc(product_train, product_users_altered,\n",
    "                  [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)], product_test)[0]\n",
    "\n",
    "    pop[i] = calc_mean_auc(product_train, product_users_altered,\n",
    "                  [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)], product_test)[1]\n",
    "    \n",
    "check = pd.Series(auc)\n",
    "check[check == check.max()]\n",
    "print('best factor:', check[check == check.max()].index.values)\n",
    "print('best ROC AUC:', check[check == check.max()].values)\n",
    "\n",
    "pop = pd.Series(pop)\n",
    "print('baseline:', pop.iloc[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_factor = check[check == check.max()].index.values[0]\n",
    "### plug in the best factor below to get the model\n",
    "model = implicit.lmf.LogisticMatrixFactorization(factors=best_factor, regularization=0.01, iterations=100)\n",
    "alpha_val = 15\n",
    "data_conf = (product_train * alpha_val).astype('double')\n",
    "model.fit(product_train, show_progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set something and Print something..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Actual group-------------------\n",
      "101688    #SalesforceSaturday #ATX\n",
      "101788    #SalesforceSaturday #ATX\n",
      "Name: group.name, dtype: object\n",
      "------------Actual group-------------------\n",
      "#SalesforceSaturday #ATX\n",
      "EFF-Austin\n",
      "Austin Filmmakers and Entrepreneurs\n",
      "Interested In Austin Real Estate?\n",
      "We love Austen in Austin\n",
      "JUICE CAMP!         Optimal Wellbeing by Eating Living Foods\n",
      "Longhorn Lockpicking Club\n",
      "Empathy Art, Embody Yoga (Austin)\n",
      "Austin LLVM Meetup\n",
      "Austin Solo Female Travel Group\n"
     ]
    }
   ],
   "source": [
    "test=pd.merge(data, events[['group.name','group.id']], left_on = 'group_id', right_on = 'group.id', how = 'inner')\n",
    "test=test.drop_duplicates()\n",
    "\n",
    "# raeding chinese books group - 26243452\n",
    "\n",
    "group_id = 300\n",
    "n_similar = 10 # getting the top ten similar items\n",
    "print (\"------------Actual group-------------------\")\n",
    "print (test[test['grp_id'] == group_id]['group.name'])\n",
    "print (\"------------Actual group-------------------\")\n",
    "\n",
    "# Use implicit to get similar items.\n",
    "similar = model.similar_items(group_id, 10)\n",
    "# Print the names of our most similar artists\n",
    "for group in similar:\n",
    "    idx, score = group\n",
    "    print (test['group.name'].loc[test.grp_id == idx].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>rsvp_sum</th>\n",
       "      <th>rsvp_total</th>\n",
       "      <th>user_id</th>\n",
       "      <th>grp_id</th>\n",
       "      <th>group.name</th>\n",
       "      <th>group.id</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17436</th>\n",
       "      <td>651345</td>\n",
       "      <td>37066322</td>\n",
       "      <td>492</td>\n",
       "      <td>4.275760</td>\n",
       "      <td>428</td>\n",
       "      <td>29</td>\n",
       "      <td>Austin Taoist Tai ChiÂ®</td>\n",
       "      <td>651345</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85006</th>\n",
       "      <td>19833657</td>\n",
       "      <td>8822886</td>\n",
       "      <td>1170</td>\n",
       "      <td>8.799110</td>\n",
       "      <td>178</td>\n",
       "      <td>295</td>\n",
       "      <td>Dragon's Lair Events Meet-Up</td>\n",
       "      <td>19833657</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89654</th>\n",
       "      <td>19833657</td>\n",
       "      <td>199446871</td>\n",
       "      <td>1132</td>\n",
       "      <td>8.545589</td>\n",
       "      <td>890</td>\n",
       "      <td>295</td>\n",
       "      <td>Dragon's Lair Events Meet-Up</td>\n",
       "      <td>19833657</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91978</th>\n",
       "      <td>19833657</td>\n",
       "      <td>235280912</td>\n",
       "      <td>1096</td>\n",
       "      <td>8.305411</td>\n",
       "      <td>1052</td>\n",
       "      <td>295</td>\n",
       "      <td>Dragon's Lair Events Meet-Up</td>\n",
       "      <td>19833657</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98950</th>\n",
       "      <td>19833657</td>\n",
       "      <td>277019056</td>\n",
       "      <td>966</td>\n",
       "      <td>7.438102</td>\n",
       "      <td>1233</td>\n",
       "      <td>295</td>\n",
       "      <td>Dragon's Lair Events Meet-Up</td>\n",
       "      <td>19833657</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106087</th>\n",
       "      <td>20745463</td>\n",
       "      <td>163824162</td>\n",
       "      <td>777</td>\n",
       "      <td>6.177168</td>\n",
       "      <td>724</td>\n",
       "      <td>321</td>\n",
       "      <td>Keep Austin Dancing Meetup</td>\n",
       "      <td>20745463</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121014</th>\n",
       "      <td>21989676</td>\n",
       "      <td>209047871</td>\n",
       "      <td>1350</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>939</td>\n",
       "      <td>333</td>\n",
       "      <td>Kontenders Poker of Austin</td>\n",
       "      <td>21989676</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122388</th>\n",
       "      <td>22278349</td>\n",
       "      <td>221608129</td>\n",
       "      <td>901</td>\n",
       "      <td>7.004448</td>\n",
       "      <td>991</td>\n",
       "      <td>335</td>\n",
       "      <td>The Jungle Movement Academy</td>\n",
       "      <td>22278349</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126893</th>\n",
       "      <td>27605326</td>\n",
       "      <td>13963536</td>\n",
       "      <td>537</td>\n",
       "      <td>4.575982</td>\n",
       "      <td>350</td>\n",
       "      <td>399</td>\n",
       "      <td>North Austin Sound Bath &amp; Crystal Healing Events</td>\n",
       "      <td>27605326</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        group_id  member_id  rsvp_sum  rsvp_total  user_id  grp_id  \\\n",
       "17436     651345   37066322       492    4.275760      428      29   \n",
       "85006   19833657    8822886      1170    8.799110      178     295   \n",
       "89654   19833657  199446871      1132    8.545589      890     295   \n",
       "91978   19833657  235280912      1096    8.305411     1052     295   \n",
       "98950   19833657  277019056       966    7.438102     1233     295   \n",
       "106087  20745463  163824162       777    6.177168      724     321   \n",
       "121014  21989676  209047871      1350   10.000000      939     333   \n",
       "122388  22278349  221608129       901    7.004448      991     335   \n",
       "126893  27605326   13963536       537    4.575982      350     399   \n",
       "\n",
       "                                              group.name  group.id  rank  \n",
       "17436                            Austin Taoist Tai ChiÂ®    651345   9.0  \n",
       "85006                       Dragon's Lair Events Meet-Up  19833657   2.0  \n",
       "89654                       Dragon's Lair Events Meet-Up  19833657   3.0  \n",
       "91978                       Dragon's Lair Events Meet-Up  19833657   4.0  \n",
       "98950                       Dragon's Lair Events Meet-Up  19833657   5.0  \n",
       "106087                        Keep Austin Dancing Meetup  20745463   7.0  \n",
       "121014                        Kontenders Poker of Austin  21989676   1.0  \n",
       "122388                       The Jungle Movement Academy  22278349   6.0  \n",
       "126893  North Austin Sound Bath & Crystal Healing Events  27605326   8.0  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top member\n",
    "test['rank'] = test.rsvp_total.rank(ascending = False, method='max') \n",
    "test_1 = test[test['rank'] <10]\n",
    "test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PrimeTime</td>\n",
       "      <td>8.233041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiking &amp; Outdoors for Singles</td>\n",
       "      <td>7.464305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Keep Austin Dancing Meetup</td>\n",
       "      <td>5.878881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agile Austin</td>\n",
       "      <td>5.791011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Shamanic Community of Austin</td>\n",
       "      <td>4.892706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Women Who Code Austin</td>\n",
       "      <td>4.873633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Austin Dance Lessons and Social Events</td>\n",
       "      <td>4.693676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Austin Kizomba dance and Social Events</td>\n",
       "      <td>4.544304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Central Texas Boardgames Meetup</td>\n",
       "      <td>4.497772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Learning Data Science in R</td>\n",
       "      <td>3.984197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   artist     score\n",
       "0                               PrimeTime  8.233041\n",
       "1           Hiking & Outdoors for Singles  7.464305\n",
       "2              Keep Austin Dancing Meetup  5.878881\n",
       "3                            Agile Austin  5.791011\n",
       "4        The Shamanic Community of Austin  4.892706\n",
       "5                   Women Who Code Austin  4.873633\n",
       "6  Austin Dance Lessons and Social Events  4.693676\n",
       "7  Austin Kizomba dance and Social Events  4.544304\n",
       "8         Central Texas Boardgames Meetup  4.497772\n",
       "9              Learning Data Science in R  3.984197"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "member_id = 277019056\n",
    "user_id = test[test['member_id'] == member_id]['user_id'].values[0]\n",
    "\n",
    "# Use the implicit recommender.\n",
    "recommended = model.recommend(user_id, sparse_user_item,N = 10,filter_already_liked_items = False)\n",
    "\n",
    "artists = []\n",
    "scores = []\n",
    "\n",
    "# Get artist names from ids\n",
    "for item in recommended:\n",
    "    idx, score = item\n",
    "    artists.append(test['group.name'].loc[test.grp_id == idx].iloc[0])\n",
    "    scores.append(score)\n",
    "\n",
    "# Create a dataframe of artist names and scores\n",
    "recommendations = pd.DataFrame({'artist': artists, 'score': scores})\n",
    "\n",
    "recommendations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
